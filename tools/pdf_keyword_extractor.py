"""
PDF é—œéµå­—æ“·å–å·¥å…·
å¾ PDF å‰ä¸‰é æ“·å–å‹è™Ÿã€æš±ç¨±ã€é—œéµå­—ï¼Œç”¨æ–¼å»ºç«‹ KEYWORD_MAP
"""

import os
import re
import json
from pathlib import Path

try:
    import fitz  # PyMuPDF
except ImportError:
    print("è«‹å®‰è£ PyMuPDF: pip install pymupdf")
    exit(1)


# ä¸‰æ˜Ÿè¢å¹•å‹è™Ÿè¦å‰‡
MODEL_PATTERNS = [
    # å®Œæ•´å‹è™Ÿ (LSé–‹é ­)
    r'LS\d{2}[A-Z]{2}\d{3}[A-Z]{2}[A-Z]{4}',  # LS32DG802SCXZW
    r'LS\d{2}[A-Z]{2}\d{3}[A-Z]+',              # LS32DG802SC
    
    # ç°¡åŒ–å‹è™Ÿ
    r'S\d{2}[A-Z]{2}\d{3}[A-Z]{2}',             # S32DG802SC
    r'S\d{2}[A-Z]\d[A-Z]?',                     # S32G8, S27M7
    
    # Gç³»åˆ—ä»£è™Ÿ
    r'G\d{2}[A-Z]{2,3}',                        # G80SD, G81SF, G95SC
    r'G\d{1,2}[A-Z]?',                          # G9, G8, G7, G5
    
    # Mç³»åˆ—ä»£è™Ÿ  
    r'M\d{2}[A-Z]?',                            # M80D, M70D
    r'M\d',                                      # M9, M8, M7, M5
    
    # Sç³»åˆ—ä»£è™Ÿ
    r'S\d{2}',                                   # S90, S80
]

# ç³»åˆ—æš±ç¨±é—œéµå­—
SERIES_KEYWORDS = [
    'Odyssey', 'ViewFinity', 'Smart Monitor', 'SmartMonitor',
    'OLED', 'Neo', 'Odyssey3D', '3D',
    'G9', 'G8', 'G7', 'G6', 'G5',
    'M9', 'M8', 'M7', 'M5',
    'S9', 'S8', 'S6',
]

# è¦æ ¼é—œéµå­—
SPEC_KEYWORDS = [
    # å°ºå¯¸
    '27å‹', '32å‹', '34å‹', '43å‹', '49å‹', '55å‹', '57å‹',
    '27"', '32"', '34"', '43"', '49"', '55"', '57"',
    
    # è§£æåº¦
    '4K', '2K', '5K', 'UHD', 'QHD', 'WQHD', 'DQHD', 'DUHD', 'FHD',
    '3840x2160', '2560x1440', '5120x1440', '5120x2880',
    
    # é¢æ¿
    'OLED', 'QD-OLED', 'VA', 'IPS', 'MiniLED', 'Mini LED',
    
    # æ›²ç‡
    '1000R', '1800R', 'æ›²é¢', 'Curved',
    
    # æ›´æ–°ç‡
    '144Hz', '165Hz', '180Hz', '240Hz', '360Hz',
    
    # åŠŸèƒ½
    'HDR', 'FreeSync', 'G-Sync', 'Tizen', 'SmartThings',
]


def extract_text_from_pdf(pdf_path: str, max_pages: int = 3) -> str:
    """æ“·å– PDF å‰ N é æ–‡å­—"""
    try:
        doc = fitz.open(pdf_path)
        text = ""
        pages_to_read = min(max_pages, len(doc))
        
        for page_num in range(pages_to_read):
            page = doc[page_num]
            text += page.get_text() + "\n"
        
        doc.close()
        return text
    except Exception as e:
        print(f"âŒ è®€å–å¤±æ•— {pdf_path}: {e}")
        return ""


def extract_models(text: str) -> list:
    """æ“·å–å‹è™Ÿ"""
    models = set()
    text_upper = text.upper()
    
    for pattern in MODEL_PATTERNS:
        matches = re.findall(pattern, text_upper)
        models.update(matches)
    
    # éæ¿¾å¤ªçŸ­æˆ–å¤ªé€šç”¨çš„
    return sorted([m for m in models if len(m) >= 2])


def extract_series(text: str) -> list:
    """æ“·å–ç³»åˆ—åç¨±"""
    series = set()
    text_upper = text.upper()
    
    for keyword in SERIES_KEYWORDS:
        if keyword.upper() in text_upper:
            series.add(keyword)
    
    return sorted(series)


def extract_specs(text: str) -> list:
    """æ“·å–è¦æ ¼é—œéµå­—"""
    specs = set()
    text_upper = text.upper()
    
    for keyword in SPEC_KEYWORDS:
        if keyword.upper() in text_upper:
            specs.add(keyword)
    
    return sorted(specs)


def analyze_pdf(pdf_path: str) -> dict:
    """åˆ†æå–®ä¸€ PDF"""
    text = extract_text_from_pdf(pdf_path, max_pages=3)
    
    if not text:
        return None
    
    result = {
        "file": os.path.basename(pdf_path),
        "models": extract_models(text),
        "series": extract_series(text),
        "specs": extract_specs(text),
        "suggested_keywords": [],
    }
    
    # å»ºè­°é—œéµå­— (å„ªå…ˆé †åºï¼šå®Œæ•´å‹è™Ÿ > ç°¡åŒ–å‹è™Ÿ > ç³»åˆ—å)
    suggested = []
    
    # å„ªå…ˆä½¿ç”¨ G/M é–‹é ­çš„ç°¡åŒ–å‹è™Ÿ
    for m in result["models"]:
        if re.match(r'^G\d{2}[A-Z]{2,3}$', m):  # G80SD, G81SF
            suggested.append(m)
        elif re.match(r'^LS\d{2}', m):  # å®Œæ•´å‹è™Ÿ
            suggested.append(m)
    
    # åŠ å…¥ç³»åˆ—å
    for s in result["series"]:
        if s not in suggested:
            suggested.append(s)
    
    result["suggested_keywords"] = suggested[:5]  # æœ€å¤š 5 å€‹
    
    return result


def analyze_folder(folder_path: str) -> list:
    """åˆ†æè³‡æ–™å¤¾å…§æ‰€æœ‰ PDF"""
    results = []
    folder = Path(folder_path)
    
    if not folder.exists():
        print(f"âŒ è³‡æ–™å¤¾ä¸å­˜åœ¨: {folder_path}")
        return results
    
    pdf_files = list(folder.glob("*.pdf")) + list(folder.glob("*.PDF"))
    
    if not pdf_files:
        print(f"âš ï¸ æ²’æœ‰æ‰¾åˆ° PDF æª”æ¡ˆ: {folder_path}")
        return results
    
    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} å€‹ PDF æª”æ¡ˆ\n")
    
    for pdf_path in sorted(pdf_files):
        print(f"ğŸ” åˆ†æä¸­: {pdf_path.name}")
        result = analyze_pdf(str(pdf_path))
        
        if result:
            results.append(result)
            print(f"   å‹è™Ÿ: {', '.join(result['models'][:5]) or 'ç„¡'}")
            print(f"   ç³»åˆ—: {', '.join(result['series']) or 'ç„¡'}")
            print(f"   å»ºè­°é—œéµå­—: {', '.join(result['suggested_keywords']) or 'ç„¡'}")
            print()
    
    return results


def generate_keyword_map(results: list) -> dict:
    """ç”Ÿæˆ KEYWORD_MAP æ ¼å¼"""
    keyword_map = {}
    
    for r in results:
        filename = r["file"]
        
        for kw in r["suggested_keywords"]:
            if kw not in keyword_map:
                keyword_map[kw] = []
            if filename not in keyword_map[kw]:
                keyword_map[kw].append(filename)
    
    return keyword_map


def main():
    import argparse
    
    parser = argparse.ArgumentParser(description="PDF é—œéµå­—æ“·å–å·¥å…·")
    parser.add_argument("path", help="PDF æª”æ¡ˆæˆ–è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--output", "-o", help="è¼¸å‡º JSON æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--pages", "-p", type=int, default=3, help="è®€å–é æ•¸ (é è¨­: 3)")
    
    args = parser.parse_args()
    path = Path(args.path)
    
    if path.is_file():
        result = analyze_pdf(str(path))
        if result:
            print(json.dumps(result, ensure_ascii=False, indent=2))
    elif path.is_dir():
        results = analyze_folder(str(path))
        
        if results:
            # ç”Ÿæˆ KEYWORD_MAP
            keyword_map = generate_keyword_map(results)
            
            print("=" * 50)
            print("ğŸ“Š KEYWORD_MAP å»ºè­°")
            print("=" * 50)
            print(json.dumps(keyword_map, ensure_ascii=False, indent=2))
            
            if args.output:
                output_data = {
                    "files": results,
                    "keyword_map": keyword_map,
                }
                with open(args.output, "w", encoding="utf-8") as f:
                    json.dump(output_data, f, ensure_ascii=False, indent=2)
                print(f"\nâœ… å·²è¼¸å‡ºè‡³: {args.output}")
    else:
        print(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {path}")


if __name__ == "__main__":
    main()
